{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed45cd78",
   "metadata": {},
   "source": [
    "## üß†üîó SciKGExtract: Agentic Pipeline for Scientific Knowledge Graph Extraction - Example Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8f3f2",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the **SciKGExtract** to extract structured knowledge from scientific documents, normalize the extracted knowledge with external databases like [PubChem](https://pubchem.ncbi.nlm.nih.gov/), evaluate the quality of the extraction, refine the extraction based on feedbacks and finally populate an ORKG knowledge graph.\n",
    "\n",
    "The SciKGExtract framework leverages an **Agentic Pipeline architecture** with sequential agent execution to perform the various tasks involved in the knowledge extraction process. The overall execution is orchestrated by an Orchestrator Agent, which coordinates the different components of the pipeline including extraction, normalization, evaluation, refinement, and KG population. We will see how each of these components/agents work together to achieve the final goal of populating a knowledge graph with high-quality structured data extracted from scientific literature.\n",
    "\n",
    "We will walk through the process step-by-step, using the **ZnO ALD processes** extraction as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822198cb",
   "metadata": {},
   "source": [
    "#### üìã Overview\n",
    "We will explore the following scenarios to demonstrate the capabilities of SciKGExtract:\n",
    "1. **Basic Structured Knowledge Extraction** ‚Üí Extract structured knowledge from scientific documents without normalization, evaluation, or refinement.\n",
    "2. **Knowledge Extraction with Normalization** ‚Üí Extract structured knowledge and normalize it using external databases like PubChem.\n",
    "3. **Knowledge Extraction with Normalization, Evaluation, and Refinement** ‚Üí Extract structured knowledge, normalize it, evaluate the quality of the extraction, and refine it based on feedback.\n",
    "4. **Populating an ORKG Knowledge Graph** ‚Üí Populate an ORKG knowledge graph with the refined structured knowledge extracted from scientific documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fd29b",
   "metadata": {},
   "source": [
    "#### ‚öôÔ∏è Section 1: Initial Configurations\n",
    "We will start with some initial configurations necessary for the extraction process. The configurations includes setting up the LLM models, defining the input and output directories, process descriptions for ZnO ALD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43571abc",
   "metadata": {},
   "source": [
    "##### üì¶ Import Necessary Packages and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2394b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the parent directory to sys.path\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Apply nest_asyncio to allow nested event loops\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94c0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Imports\n",
    "import json\n",
    "\n",
    "# SciKG-Extract Config Imports\n",
    "from scikg_extract.config.process.processConfig import ProcessConfig\n",
    "from scikg_extract.config.llm.envConfig import EnvConfig\n",
    "\n",
    "# Import Utilities\n",
    "from scikg_extract.utils.log_handler import LogHandler\n",
    "from scikg_extract.utils.file_utils import read_json_file, read_text_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1d6b3",
   "metadata": {},
   "source": [
    "##### üìù Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80d50411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Initialize Module Logging\n",
    "logger = LogHandler.setup_module_logging(\"scikg_extract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5a9ae",
   "metadata": {},
   "source": [
    "##### ü§ñ Setting Up LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3ba4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM to be used for structured knowledge extraction\n",
    "llm_name_extraction = \"gpt-4o\"\n",
    "\n",
    "# LLM to be used for Normalization especially for chemical entities disambiguation\n",
    "llm_name_normalization = \"gpt-5\"\n",
    "\n",
    "# LLM to be used for Reflection/Evaluation of the extracted knowledge\n",
    "llm_name_reflection = \"gpt-4o\"\n",
    "\n",
    "# LLM to be used for Feedback formulation based on the evaluation results\n",
    "llm_name_feedback = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115115d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API Key and Organization ID\n",
    "EnvConfig.OPENAI_api_key = '<insert-your-openai-key>'\n",
    "EnvConfig.OPENAI_organization_id = '<insert-your-openi-organization-id>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab3d66d",
   "metadata": {},
   "source": [
    "##### üìÇ Input and Output Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c058e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scientific document containing ZnO ALD experimental processes in markdown format\n",
    "scientific_docs_dir = \"../data/research-papers/ALD/markdown/ZnO-IGZO-papers/experimental-usecase/ZnO/ZnEt2 - H2O/2 Lujala et al.md\"\n",
    "scientific_document = read_text_file(scientific_docs_dir)\n",
    "\n",
    "# ALD Process Schema path for experimental processes\n",
    "process_schema_path = \"../data/schemas/ALD-experimental/ALD-experimental-schema.json\"\n",
    "process_schema = read_json_file(process_schema_path)\n",
    "\n",
    "# Domain-expert curated examples for ZnO ALD processes\n",
    "examples_path = \"../data/examples/Atomic-layer-deposition/ZnO/example1.txt\"\n",
    "examples = read_text_file(examples_path)\n",
    "\n",
    "# Manually curated PubChem synonym to CID mapping dictionary\n",
    "pubchem_lookup_dict_path = \"../data/resources/PubChem-Synonym-CID.json\"\n",
    "synonym_to_cid_mapping = read_json_file(pubchem_lookup_dict_path)\n",
    "\n",
    "# PubChem LMDB database created from PubChem CID data dump\n",
    "lmdb_pubchem_path = \"../data/external/pubchem/pubchem_cid_lmdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c520d",
   "metadata": {},
   "source": [
    "##### üß™ ZnO ALD Process Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c74eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Name\n",
    "ProcessConfig.Process_name = \"Atomic Layer Deposition\"\n",
    "\n",
    "ProcessConfig.Process_description = \"\"\"\n",
    "Atomic layer deposition (ALD) is a surface-controlled thin film deposition technique that can enable ultimate control over the film thickness, uniformity on large-area substrates and conformality on 3D (nano)structures. Each ALD cycle consists at least two half-cycles (but can be more complex), containing a precursor dose step and a co-reactant exposure step, separated by purge or pump steps. Ideally the same amount of material is deposited in each cycle, due to the self-limiting nature of the reactions of the precursor and co-reactant with the surface groups on the substrate. By carrying out a certain number of ALD cycles, the targeted film thickness can be obtained.\n",
    "\n",
    "In this extraction task, we are focusing on ZnO (Zinc Oxide) thin film deposition via ALD. A ZnO ALD (Zinc Oxide Atomic Layer Deposition) process deposits thin ZnO films through sequential, self-limiting surface reactions between a zinc precursor and an oxidant. The process typically consists of repeating ALD cycles, each containing a precursor pulse (e.g., diethylzinc (DEZ), Zn(acac)‚ÇÇ, or Zn(thd)‚ÇÇ), a purge step, an oxidant pulse (commonly H‚ÇÇO, O‚ÇÉ, or O‚ÇÇ plasma), followed by another purge. These reactions form a conformal zinc-oxygen layer per cycle with precise thickness control. The aim of a ZnO ALD process is to produce high-quality, uniform, conformal ZnO films with controlled thickness, crystallinity (amorphous or polycrystalline depending on temperature), and stoichiometry.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf06fcc",
   "metadata": {},
   "source": [
    "#### üéØ Section 2: Basic Structured Knowledge Extraction\n",
    "In this section, we will demonstrate how to perform basic structured knowledge extraction from scientific documents using the SciKGExtract framework. We will extract information related to ZnO processes from the scientific paper downloaded from [AtomicLimits Database](https://www.atomiclimits.com/alddatabase/). All the subsequent sections will use the same scientific article as an input to ensure consistency and evolutuion of the extraction process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c7ce0",
   "metadata": {},
   "source": [
    "##### üì¶ Import the Necessary Modules and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ae272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Orchestrator Agent\n",
    "from scikg_extract.agents.orchestrator_agent import orchestrate_extraction_workflow\n",
    "\n",
    "# Import Configurations\n",
    "from scikg_extract.config.agents.orchestrator import OrchestratorConfig\n",
    "from scikg_extract.config.agents.workflow import WorkflowConfig\n",
    "\n",
    "# Import Data Models\n",
    "from data.models.schema.ALD_experimental_schema import ALDProcessList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb85d8",
   "metadata": {},
   "source": [
    "##### ‚öôÔ∏è Orchestrator Agent Configuration\n",
    "The Orchestrator Agent is responsible for coordinating the different components of the extraction pipeline. We will configure it with the necessary parameters necessary for the basic extraction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd42b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize orchestrator configuration\n",
    "orchestrator_config = OrchestratorConfig(\n",
    "    llm_name=llm_name_extraction,\n",
    "    process_schema=process_schema,\n",
    "    scientific_document=scientific_document,\n",
    "    examples=examples,\n",
    "    extraction_data_model=ALDProcessList\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6c1b5",
   "metadata": {},
   "source": [
    "##### üîÄ Worflow Configuration\n",
    "The workflow configuration defines different flags that control the behavior of the extraction pipeline. For basic extraction, we will set the flags to disable normalization, evaluation, and refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac2a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Workflow configuration\n",
    "workflow_config = WorkflowConfig(normalize_extracted_data=False, clean_extracted_data=False, validate_extracted_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f526b",
   "metadata": {},
   "source": [
    "##### ‚ñ∂Ô∏è Execute the Basic Structured Knowledge Extraction Workflow\n",
    "With the configurations in place, we can now execute the basic structured knowledge extraction workflow using the SciKGExtract framework. The orchestrator agent will manage the flow of data and control between the different components of the pipeline to extract structured knowledge from the input scientific documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ed12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract knowledge using the orchestrator agent\n",
    "final_state = orchestrate_extraction_workflow(orchestrator_config, workflow_config)\n",
    "\n",
    "# Get the extracted knowledge from the final state\n",
    "extracted_knowledge = final_state[\"extracted_json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624cb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Extracted Knowledge\n",
    "print(json.dumps(extracted_knowledge, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18228e2a",
   "metadata": {},
   "source": [
    "#### üîó Knowledge Extraction with Normalization\n",
    "In this section, we will extend the basic structured knowledge extraction process by incorporating normalization of the extracted data using external databases like PubChem. Normalization helps in standardizing the extracted information, espeicially for properties like chemical names and identifiers, mapping similar entities to a common identifier from PubChem database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b814a2",
   "metadata": {},
   "source": [
    "##### ‚öôÔ∏è Orchestrator Agent Configuration\n",
    "The Orchestrator Agent configuration remains similar to the basic extraction setup with the addition of normalization properties including PubChem LMDB path containing indexed PubChem Synonyms to CID mapping for fast lookup, synonym to CID mapping dictionary containing manually curated synonyms to PubChem CIDs and the LLM model name used for normalization disambiguation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ad8ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize orchestrator configuration\n",
    "orchestrator_config = OrchestratorConfig(\n",
    "    llm_name=llm_name_extraction,\n",
    "    normalization_llm_name=llm_name_normalization,\n",
    "    process_schema=process_schema,\n",
    "    scientific_document=scientific_document,\n",
    "    examples=examples,\n",
    "    extraction_data_model=ALDProcessList,\n",
    "    pubchem_lmdb_path=lmdb_pubchem_path,\n",
    "    synonym_to_cid_mapping=synonym_to_cid_mapping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da63590",
   "metadata": {},
   "source": [
    "##### üîÄ Workflow Configuration\n",
    "The workflow configuration for normalization will enable the normalization flag while keeping evaluation and refinement disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6c91e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Workflow configuration\n",
    "workflow_config = WorkflowConfig(normalize_extracted_data=True, clean_extracted_data=False, validate_extracted_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca8de1f",
   "metadata": {},
   "source": [
    "##### ‚ñ∂Ô∏è Execute the Knowledge Extraction with Normalization Workflow\n",
    "With the updated configurations, we can now execute the knowledge extraction workflow with normalization enabled. The orchestrator agent will coordinate the extraction and normalization processes to produce standardized structured knowledge from the input scientific documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bcadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract knowledge using the orchestrator agent\n",
    "final_state = orchestrate_extraction_workflow(orchestrator_config, workflow_config)\n",
    "\n",
    "# Get the extracted knowledge from the final state\n",
    "normalized_extracted_knowledge = final_state[\"normalized_json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Extracted Knowledge\n",
    "print(json.dumps(normalized_extracted_knowledge, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637fe1d1",
   "metadata": {},
   "source": [
    "#### ‚úÖ Knowledge Extraction with Normalization, Evaluation, and Refinement\n",
    "In this section, we will further enhance the knowledge extraction process by incorporating LLM-as-a-Judge evaluation and refinement based on feedback. This will help improve the quality of the extracted knowledge by assessing its completeness and correctness, and refining it based on the evaluation results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7822bc",
   "metadata": {},
   "source": [
    "##### üì¶ Import the Validation Rubrics\n",
    "We will import the necessary validation rubrics that will be used by the LLM-as-a-Judge to evaluate the quality of the extracted knowledge. These rubrics are an extension of the [YESciEval framework](https://github.com/sciknoworg/YESciEval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c96183f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Rubrics Imports\n",
    "from scikg_extract.evaluation.rubrics.informativeness import Completeness, Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43dbd36",
   "metadata": {},
   "source": [
    "##### ‚öôÔ∏è Orchestrator Agent Configuration\n",
    "The orchestrator agent configuration will now include additional parameters for evaluation and refinement, including the LLM model for reflection, list of rubric names for evaluation and LLM model for feedback incorporation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89938123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize orchestrator configuration\n",
    "orchestrator_config = OrchestratorConfig(\n",
    "    llm_name=llm_name_extraction,\n",
    "    normalization_llm_name=llm_name_normalization,\n",
    "    process_schema=process_schema,\n",
    "    scientific_document=scientific_document,\n",
    "    examples=examples,\n",
    "    extraction_data_model=ALDProcessList,\n",
    "    pubchem_lmdb_path=lmdb_pubchem_path,\n",
    "    synonym_to_cid_mapping=synonym_to_cid_mapping,\n",
    "    reflection_llm_name=llm_name_reflection,\n",
    "    rubrics=[Completeness, Correctness],\n",
    "    feedback_llm_name=llm_name_feedback\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd16a77",
   "metadata": {},
   "source": [
    "##### üîÄ Workflow Configuration\n",
    "The workflow configuration now enables normalization, evaluation, and refinement flags to activate the respective components in the extraction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e185bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Workflow configuration\n",
    "workflow_config = WorkflowConfig(normalize_extracted_data=True, clean_extracted_data=False, validate_extracted_data=True, total_validation_retries=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540d9780",
   "metadata": {},
   "source": [
    "##### ‚ñ∂Ô∏è Execute the Extraction Workflow with Normalization, Evaluation, and Refinement\n",
    "With all the configurations set, we can now execute the knowledge extraction workflow that includes normalization, evaluation, and refinement. The orchestrator agent will oversee the entire process, ensuring that each component functions correctly and that the final output is a high-quality structured knowledge representation extracted from the scientific documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract knowledge using the orchestrator agent\n",
    "final_state = orchestrate_extraction_workflow(orchestrator_config, workflow_config)\n",
    "\n",
    "# Get the extracted knowledge from the final state\n",
    "normalized_extracted_knowledge = final_state[\"normalized_json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ffbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Extracted Knowledge\n",
    "print(json.dumps(normalized_extracted_knowledge, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awases",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
